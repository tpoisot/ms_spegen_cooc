A second measure of the distribution of specificities within a network
is its evenness, denoted $E$. We define $\mathbf{s}'$ as all the unique
values of $\mathbf{s}$, rounded to the second decimal place. $U$ is all the
possible values that $\mathbf{s}'$ can take, and $u$ each particular value
of $\mathbf{s}'$. For each $u$, we calculate $p(u)$ as the probability
of any randomly chosen element of $U$ having the value $u$. For example,
if $\mathbf{s}' = [0.1, 1, 1, 0, 0.4]$, then $U = [0, 0.1, 0.4, 1]$,
$p(u = 1) = 2 / 5$, and $p(u = 0) = 1 / 5$. With this information, we
calculate the self-information [@shannon_mathematical_1948] of $u$ as $I(u)
= -\mathrm{ln}(u)$, and based on these two sets of values, we calculate the
Shannonâ€™s entropy of the distribution of specificity values as
